{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sealed-chart",
   "metadata": {},
   "source": [
    "#  Basic Data Science in Python - Exercises 21/9  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture as GM\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-pearl",
   "metadata": {},
   "source": [
    "### Exercise 1: Data Preprocessing\n",
    "Let us brush up on the Data Preprocessing we learnt in the last course. \n",
    "\n",
    "###### Task 1\n",
    "First, import the dataset $\\texttt{netflix_titles.csv}$ from the data folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-principle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "operating-intervention",
   "metadata": {},
   "source": [
    "##### Task 2\n",
    "There are some null-values in the duration column. This is because these values have turned up in the rating coloumn instead. Move these duration values from the rating coloumn to the duration coloumn. You can replace them with NaN for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-popularity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "federal-bachelor",
   "metadata": {},
   "source": [
    "###### Task 3\n",
    "Create two new data frames, one for movies and one for TV-shows. Create a barplot of the age rating of the movies on Netflix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-liver",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-colombia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "clinical-aluminum",
   "metadata": {},
   "source": [
    "##### Task 4\n",
    "Let's see if the percentage of horror movies rated R are higher than the percentage of general movies rated R. Find the percentage of horror movies rated R, and compare that to the percentage of movies rated R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-november",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "awful-transformation",
   "metadata": {},
   "source": [
    "### Exercise 2: Statistics with Python\n",
    "Use pandas to calculate the contingency table, and use the $\\texttt{scipy.stats}$ library to perform a Chi-Squared test for independence on the Titanic dataset, with respects to the class of the passangers, and how many survived. What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-treatment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "titanic = pd.read_csv(\"../data/titanic.csv\")\n",
    "contingency = None\n",
    "x = titanic[\"Pclass\"]\n",
    "y = titanic[\"Survived\"]\n",
    "### YOUR CODE HERE - calculate the contingency table\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "#code to visualize the contingency table\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(contingency, annot=True, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-israeli",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE - perform chi2 test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-parameter",
   "metadata": {},
   "source": [
    "### Exercise 3: The Hello World of Scikit Learn\n",
    "Let's get comfortable with using methods from scikit learn. It is often a good idea to take a look at the [documentation](https://scikit-learn.org/stable/) of a method before using it. Take a look at the documentation for [k-Means](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) and use this method to cluster the below dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = datasets.make_blobs(n_samples=100, centers=2, n_features=2, center_box=(0, 10), cluster_std=0.7)\n",
    "clusters = [0 for _ in range(X.shape[0])]\n",
    "### YOUR CODE HERE\n",
    "\n",
    "### YOUR CODE HERE\n",
    "plt.scatter(*X.T, c=clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-track",
   "metadata": {},
   "source": [
    "### Exercise 4: PCA and EM (Handin)\n",
    "Use Principal Component Analysis to reduce the dimensionality of the Iris Dataset to 2D, and then use Gaussian Mixtures to assign the points to three clusters. Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-passport",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-blade",
   "metadata": {},
   "source": [
    "### Exercise 5: PCA as Noise Filtering\n",
    "Principal Component Analysis can be used to filter noisy data. Below is a dataset consisting of handwritten digits, with added noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(digits, label=\"\"):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    plt.title(label)\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(16):\n",
    "        ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "        ax.imshow(digits[i].reshape(8,8), cmap=plt.cm.binary, interpolation='nearest')\n",
    "\n",
    "#Original dataset\n",
    "digits = datasets.load_digits().data\n",
    "plot_digits(digits, label=\"original data\")\n",
    "\n",
    "#Dataset with noise\n",
    "np.random.seed(42)\n",
    "noisy_digits = np.random.normal(digits, 4)\n",
    "plot_digits(noisy_digits, label=\"data with noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-attention",
   "metadata": {},
   "source": [
    "Use PCA to filter some of the noise out. You can do this by first computing the principal components, and then inverse transform these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-artist",
   "metadata": {},
   "source": [
    "### Exercise 6: Implement k-Means (Hard)\n",
    "\n",
    "Implement a simple k-Means algorithm, and test your implementation on the below dataset. Just run for a fixed number of iterations $\\texttt{max_iter}$, so don't worry about convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-promotion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = datasets.make_blobs(n_samples=100, centers=2, n_features=2, center_box=(0, 10), cluster_std=0.7)\n",
    "plt.scatter(*X.T, c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMeans(X, k=2, max_iter = 100):\n",
    "    \n",
    "    #initialize random clusters\n",
    "    clusters = [0 for _ in range(X.shape[0])]\n",
    "    mu = X[np.random.choice(X.shape[0], k)]\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    return clusters\n",
    "plt.scatter(*X.T, c=kMeans(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
